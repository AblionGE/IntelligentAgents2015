# Introduction

In this programming exercise, we implement the Pickup and Delivery problem with reactive agents. These agents will decide to deliver or not a task in a city depending on an offline computation of a Markov Decision Process. This MDP permits the agents to know in each state what to do to maximise the benefit of each action according to the reward given by the task and the cost of going to a specific city.

In the next sections, we will define the representation of states and actions, then we will define of we build the different matrices that are necessary to have a reactive agent. Finally, we will present different results given by our program.

# Representation of states and actions

# Definitions of reward and probability transition tables

# Results
